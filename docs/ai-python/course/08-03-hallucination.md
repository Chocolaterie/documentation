---
id: hallucination-ia
title: Hallucination en IA
sidebar_position: 9
---

# L’hallucination en intelligence artificielle

L’**hallucination** en IA, ce n’est pas un bug ou un délire,  
c’est quand un modèle **invente une réponse** qui **semble vraie**,  
mais qui est en réalité **fausse ou sans fondement**.

---

## Définition simple

> Une hallucination, c’est quand une IA dit quelque chose qui **sonne juste**,  
> mais qui est **complètement inventé**.

Ce phénomène est fréquent avec les **modèles de langage** (comme ChatGPT),  
mais peut aussi arriver avec des IA qui **génèrent des textes, des images ou des codes.**


## Exemple ultra simple

### Tu poses cette question à une IA :

> "Qui a inventé l’imprimante 3D en 1815 ?"

L’IA répond :

> "L’imprimante 3D a été inventée en 1815 par Jacques Boulanger, un inventeur français passionné de mécanique."

**Problème :**
- L’impression 3D n’existait pas en 1815
- Jacques Boulanger est un personnage inventé
- La réponse **semble crédible**, mais est **fausse**

## Pourquoi ça arrive ?

Les IA comme ChatGPT ne "savent" rien.  
Elles ne cherchent pas dans une base de données.  
Elles **prédisent le mot suivant** en fonction des mots précédents.  
Elles sont donc capables de **fabriquer un discours fluide**, mais pas toujours exact.

## Analogie pédagogique

> C’est comme un élève qui veut toujours répondre,  
> même quand il ne connaît pas la réponse.  
> Plutôt que dire "Je ne sais pas",  
> il préfère **inventer une réponse qui a l’air intelligente**.

## Dans quels cas ça arrive ?

| Situation                          | Risque d’hallucination élevé |
|-----------------------------------|------------------------------|
| Sujet très spécifique ou rare     | Oui                          |
| Question piégée ou impossible     | Oui                          |
| Pas assez d’informations dans la requête | Oui                  |
| Sujets très courants              | Faible à moyen               |


## Comment limiter les hallucinations ?

- Poser des questions **claires et précises**
- Demander des **sources ou des citations**
- Croiser les réponses avec des **vérifications humaines**
- Ne pas faire confiance aveuglément à une IA

## À retenir

> Une IA peut parler **avec confiance**,  
> mais cela **ne veut pas dire qu’elle a raison**.

C’est à l’humain de rester **critique, vigilant**,  
et de ne jamais oublier :  
**l’IA peut halluciner.**
